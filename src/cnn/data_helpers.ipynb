{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_files = ['../data/data_by_ocean/eclipse/raw/0_summary_description.csv',\n",
    "              '../data/data_by_ocean/eclipse/raw/1_summary_description.csv',\n",
    "              '../data/data_by_ocean/eclipse/raw/2_summary_description.csv',\n",
    "              '../data/data_by_ocean/eclipse/raw/3_summary_description.csv',\n",
    "              '../data/data_by_ocean/eclipse/raw/4_summary_description.csv',\n",
    "              '../data/data_by_ocean/eclipse/raw/5_summary_description.csv',\n",
    "              '../data/data_by_ocean/eclipse/raw/6_summary_description.csv',\n",
    "              '../data/data_by_ocean/eclipse/raw/7_summary_description.csv',\n",
    "              '../data/data_by_ocean/eclipse/raw/8_summary_description.csv']\n",
    "labels_files = ['../data/data_by_ocean/eclipse/raw/0_bug_id_date_who.csv',\n",
    "                '../data/data_by_ocean/eclipse/raw/1_bug_id_date_who.csv',\n",
    "                '../data/data_by_ocean/eclipse/raw/2_bug_id_date_who.csv',\n",
    "                '../data/data_by_ocean/eclipse/raw/3_bug_id_date_who.csv',\n",
    "                '../data/data_by_ocean/eclipse/raw/4_bug_id_date_who.csv',\n",
    "                '../data/data_by_ocean/eclipse/raw/5_bug_id_date_who.csv',\n",
    "                '../data/data_by_ocean/eclipse/raw/6_bug_id_date_who.csv',\n",
    "                '../data/data_by_ocean/eclipse/raw/7_bug_id_date_who.csv',\n",
    "                '../data/data_by_ocean/eclipse/raw/8_bug_id_date_who.csv']\n",
    "test_data_files = ['../data/data_by_ocean/eclipse/raw/9_summary_description.csv',\n",
    "                   '../data/data_by_ocean/eclipse/raw/10_summary_description.csv']\n",
    "test_labels_files = ['../data/data_by_ocean/eclipse/raw/9_bug_id_date_who.csv',\n",
    "                     '../data/data_by_ocean/eclipse/raw/10_bug_id_date_who.csv']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def clean_str(string):\n",
    "    \"\"\"\n",
    "    Tokenization/string cleaning for all datasets except for SST.\n",
    "    Original taken from https://github.com/yoonkim/CNN_sentence/blob/master/process_data.py\n",
    "    \"\"\"\n",
    "    string = re.sub(r\"[^A-Za-z0-9(),!?\\'\\`]\", \" \", string)\n",
    "    string = re.sub(r\"\\'s\", \" \\'s\", string)\n",
    "    string = re.sub(r\"\\'ve\", \" \\'ve\", string)\n",
    "    string = re.sub(r\"n\\'t\", \" n\\'t\", string)\n",
    "    string = re.sub(r\"\\'re\", \" \\'re\", string)\n",
    "    string = re.sub(r\"\\'d\", \" \\'d\", string)\n",
    "    string = re.sub(r\"\\'ll\", \" \\'ll\", string)\n",
    "    string = re.sub(r\",\", \" , \", string)\n",
    "    string = re.sub(r\"!\", \" ! \", string)\n",
    "    string = re.sub(r\"\\(\", \" \\( \", string)\n",
    "    string = re.sub(r\"\\)\", \" \\) \", string)\n",
    "    string = re.sub(r\"\\?\", \" \\? \", string)\n",
    "    string = re.sub(r\"\\s{2,}\", \" \", string)\n",
    "    return string.strip().lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train data length: 163611\n"
     ]
    }
   ],
   "source": [
    "data = []\n",
    "for data_file in data_files:\n",
    "    with open(data_file, 'r', encoding='latin-1') as f:\n",
    "        data.extend([s.strip() for s in f.readlines()])\n",
    "        data = [clean_str(s) for s in data]\n",
    "print('train data length: %d' % len(data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "163611\n"
     ]
    }
   ],
   "source": [
    "del labels\n",
    "labels_dfs = [pd.read_csv(f) for f in labels_files]\n",
    "labels = pd.concat(labels_dfs)\n",
    "print(len(labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     Claude_Knaus@oti.com\n",
       "1               jerome_lanneluc@fr.ibm.com\n",
       "2                     Claude_Knaus@oti.com\n",
       "3                     Claude_Knaus@oti.com\n",
       "4                        akiezun@gmail.com\n",
       "5                        akiezun@gmail.com\n",
       "6                        akiezun@gmail.com\n",
       "7                        akiezun@gmail.com\n",
       "8                        akiezun@gmail.com\n",
       "9                        akiezun@gmail.com\n",
       "10                       akiezun@gmail.com\n",
       "11                       akiezun@gmail.com\n",
       "12                       akiezun@gmail.com\n",
       "13                    Claude_Knaus@oti.com\n",
       "14                       akiezun@gmail.com\n",
       "15                       akiezun@gmail.com\n",
       "16                       akiezun@gmail.com\n",
       "17                    Claude_Knaus@oti.com\n",
       "18                    Claude_Knaus@oti.com\n",
       "19                       akiezun@gmail.com\n",
       "20                       akiezun@gmail.com\n",
       "21               philippe_mulet@fr.ibm.com\n",
       "22                       akiezun@gmail.com\n",
       "23                       akiezun@gmail.com\n",
       "24              kai-uwe_maetzel@ch.ibm.com\n",
       "25                       akiezun@gmail.com\n",
       "26                       akiezun@gmail.com\n",
       "27                    Claude_Knaus@oti.com\n",
       "28                       akiezun@gmail.com\n",
       "29                       akiezun@gmail.com\n",
       "                       ...                \n",
       "18149            michael.norman@oracle.com\n",
       "18150                   nathan@eclipse.org\n",
       "18151                       wlu@us.ibm.com\n",
       "18152                 mikekucera@gmail.com\n",
       "18153                 mikekucera@gmail.com\n",
       "18154                 mikekucera@gmail.com\n",
       "18155              matt.macivor@oracle.com\n",
       "18156             markus_keller@ch.ibm.com\n",
       "18157           steffen.pingel@tasktop.com\n",
       "18158                  ken.ryall@gmail.com\n",
       "18159                  cwindatt@ca.ibm.com\n",
       "18160                  ken.ryall@gmail.com\n",
       "18161                  emoffatt@ca.ibm.com\n",
       "18162            Michael_Rennie@ca.ibm.com\n",
       "18163                  remy.suen@gmail.com\n",
       "18164            Michael_Rennie@ca.ibm.com\n",
       "18165                     cgold@us.ibm.com\n",
       "18166              darin.eclipse@gmail.com\n",
       "18167                yves.yang@soyatec.com\n",
       "18168                   aniefer@ca.ibm.com\n",
       "18169           john.cortell@freescale.com\n",
       "18170              darius.jockel@itemis.de\n",
       "18171           cameron.bateman@oracle.com\n",
       "18172                 d_a_carver@yahoo.com\n",
       "18173                 mikekucera@gmail.com\n",
       "18174                 mikekucera@gmail.com\n",
       "18175           cameron.bateman@oracle.com\n",
       "18176    raghunathan.srinivasan@oracle.com\n",
       "18177                     cgold@us.ibm.com\n",
       "18178                  pascal@rapicorp.com\n",
       "Name: who, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels.who"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将sort-text-id排好序的文本改写成编号的形式存储起来。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(\"../data/data_by_ocean/eclipse/sort-text-id.csv\", encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data.text\n",
    "y = data.fixer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from tensorflow.contrib import learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dev_sample_index = -1 * int(0.2 * float(len(y)))\n",
    "x_train, x_dev = x[:dev_sample_index], x[dev_sample_index:]\n",
    "y_train, y_dev = y[:dev_sample_index], y[dev_sample_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "document_length_df = pd.DataFrame([len(xx.split(\" \")) for xx in x_train])\n",
    "document_length = np.int64(document_length_df.quantile(0.8))\n",
    "vocabulary_processor = learn.preprocessing.VocabularyProcessor(document_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_train = vocabulary_processor.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-1-60c1fcef09cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mt_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_train = np.array(list(vocabulary_processor.fit_transform(x_train)), dtype=np.float32)\n",
    "x_dev = np.array(list(vocabulary_processor.transform(x_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "label_processor = learn.preprocessing.VocabularyProcessor(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = np.array(list(label_processor.fit_transform(y_train)), dtype=np.float32)\n",
    "y_dev = np.array(list(label_processor.transform(y_dev)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame([y_train, y_dev]).to_csv('tmpt.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
