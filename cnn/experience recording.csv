实验方法 cnn
源码改编：https://github.com/yoonkim/CNN_sentence
源自论文：Convolutional Neural Networks for Sentence Classification
博客：http://www.wildml.com/2015/12/implementing-a-cnn-for-text-classification-in-tensorflow/
====================================================================
2017年7月31号
设计：训练到8万步
dev_sample_percentage：0.2
embedding_dim：300
filter_sizes：2,4,8,10,20,40,90,120,180,200
num_filters：10
dropout_keep_prob：0.8
l2_reg_lambda：0.3
learning_rate: 1e-4
batch_size：1024
num_epochs：2000
evaluate_every：1000
checkpoint_every：1000
num_checkpoints：1000
top_k：3
embedding_type：static_train
试验结果
训练时长：4d3h14m43s
accuracy：训练集0.9531，验证集0.5322
precision：训练集0.2907，验证集0.2907
recall：训练集0.8721，验证集0.8721
====================================================================
2017年7月12号
设计：使用全部测试集的评价指标
dev_sample_percentage：0.2
embedding_dim：300
filter_sizes：2,4,8,10,20,40,90,120,180,200
num_filters：10
dropout_keep_prob：0.8
l2_reg_lambda：0.3
learning_rate: 1e-4
batch_size：100
num_epochs：100
evaluate_every：1000
checkpoint_every：1000
num_checkpoints：1000
top_k：3
embedding_type：static
试验结果
训练时长：17h17m12s
accuracy@3：0.327
precision@3：0.159126
recall@3：0.477378
====================================================================
2017年6月25号
设计：使用static训练,将数据打乱后训练，并增加了learning rate decay
dev_sample_percentage：0.2
embedding_dim：300
filter_sizes：2,4,8,10,20,40,90,120,180,200
num_filters：10
dropout_keep_prob：0.8
l2_reg_lambda：0.3
learning_rate: 1e-4
batch_size：1024
num_epochs：2000
evaluate_every：1000
checkpoint_every：1000
num_checkpoints：1000
top_k：3
embedding_type：static
试验结果
训练时长：18h25m53s
accuracy@3：训练集:0.810,测试集：0.5800
precision@3：训练集：0.1792，测试集：0.1792
recall@3：训练集：0.5377,测试集：0.5376
====================================================================
2017年6月24号
设计：使用static_train训练
dev_sample_percentage：0.2
embedding_dim：300
filter_sizes：2,4,8,10,20,40,90,120,180,200
num_filters：10
dropout_keep_prob：0.8
l2_reg_lambda：0.3
learning_rate: 1e-4
batch_size：1024
num_epochs：2000
evaluate_every：1000
checkpoint_every：1000
num_checkpoints：1000
top_k：3
embedding_type：static_train
试验结果
训练时长：2d20h48m40s
accuracy@3：训练集:0.9706,测试集：0.6700
precision@3：训练集：0.2527，测试集：0.2526
recall@3：训练集：0.7580,测试集：0.7578
====================================================================
2017年6月21号
设计：使用static embedding训练
dev_sample_percentage：0.2
embedding_dim：300
filter_sizes：2,4,8,10,20,40,90,120,180,200
num_filters：10
dropout_keep_prob：0.8
l2_reg_lambda：0.3
learning_rate: 1e-4
batch_size：1024
num_epochs：2000
evaluate_every：1000
checkpoint_every：1000
num_checkpoints：1000
top_k：3
embedding_type：static
试验结果
训练时长：18h32m10s
accuracy@3：训练集:0.7591,测试集：0.3652
precision@3：训练集：0.1781，测试集：0.1781
recall@3：训练集：0.5343,测试集：0.5342
====================================================================
2017年6月20号
设计：加入accuracy@3，recall@3，precision@3
dev_sample_percentage：0.2
embedding_dim：300
filter_sizes：2,4,8,10,20,40,90,120,180,200
num_filters：10
dropout_keep_prob：0.8
l2_reg_lambda：0.3
learning_rate: 1e-4
batch_size：1024
num_epochs：2000
evaluate_every：1000
checkpoint_every：1000
num_checkpoints：1000
top_k：3
embedding_type：train
试验结果
训练时长：2d20h27m24s
accuracy@3：训练集:0.9706,测试集：0.5002
precision@3：训练集：0.2525,测试集：0.2525
recall@3：训练集：0.7576，测试集：0.7575
====================================================================
2017年6月7号
设计：修改filter sizes,加入正则化
dev_sample_percentage：0.2
embedding_dim：128
filter_sizes：10,100,200
num_filters：128
dropout_keep_prob：0.5
l2_reg_lambda：0.2
learning_rate: 1e-4
batch_size：1000
num_epochs：200
evaluate_every：1000
checkpoint_every：1000
num_checkpoints：500
试验结果
训练集accuracy 0.9107
测试集accuracy 0.5714
训练时间：2d0h47m32s
训练集和测试集的accuracy虽然不如以前的精度，但是从图像上看，其训练并未达到饱和，
那么还有增加训练量的机会。
====================================================================
2017年6月4号
设计：使用小婉排序之后数据
dev_sample_percentage：0.2
embedding_dim：128
filter_sizes：3,4,5
num_filters：128
dropout_keep_prob：0.5
l2_reg_lambda：0.0
learning_rate: 1e-4
batch_size：1000
num_epochs：200
evaluate_every：1000
checkpoint_every：1000
num_checkpoints：500
试验结果
训练集accuracy 0.947
测试集accuracy 0.6069
训练时间：14h53min
训练集的accuracy可以一直不断上升
但是测试集基本在15k左右便不再大幅增加
====================================================================
2017年6月3号
设计：将数据按照时间排序，并分成11份，前九份作为训练集，后二份作为测试集
所有数据都没有进过stop词过滤，没有特殊处理
vocabulary_size：1000
embedding_dim：128
filter_sizes：3,4,5
num_filters：128
dropout_keep_prob：0.5
l2_reg_lambda：0.0
batch_size：1000
num_epochs：200
dev_sample_percentage：0.2
evaluate_every：1000
checkpoint_every：1000
num_checkpoints：500
试验结果
训练集accuracy 0.9296
测试集accuracy 0.5862
训练时间：1d11h49m
训练集accuracy还有增加的余地
但是测试集在在10k左右便停止增长，而且出现了负增长
====================================================================
2017年5月28号
设计：更换时间序列的原始数据集
vocabulary_size：1000
embedding_dim：128
filter_sizes：3,4,5
num_filters：128
dropout_keep_prob：0.5
l2_reg_lambda：0.0
batch_size：100
num_epochs：200
dev_sample_percentage：0.2
evaluate_every：100
checkpoint_every：100
num_checkpoints：500
试验结果
结果很不理想，accuracy不到0.1，损失在4.5和之间
从训练数据来看，训练并没有收敛，accuracy基本在0.01以下
失败分析：
label数据读入错误，只读到一份数据，导致实验只训练了3.8k次
=================================================================
2015年5月24号
设计：修正了测试集的设计，
vocabulary_size：1000
embedding_dim：128
filter_sizes：3,4,5
num_filters：128
dropout_keep_prob：0.5
l2_reg_lambda：0.0
batch_size：1000
num_epochs：200
dev_sample_percentage：0.2
evaluate_every：1000
checkpoint_every：10000
num_checkpoints：500
试验结果
训练集的accuracy很高，将近于1
测试集的accuracy基本稳定在80%左右
随着测试次数不断增加，其效果越来越差，基本在20K结果接近最好
可以到达82%，基本上要高于81%，比平均值要高
================================================================
2017年5月22号
第一次试验
试验参数
vocabulary_size：1000
embedding_dim：128
filter_sizes：3,4,5
num_filters：128
dropout_keep_prob：0.5
l2_reg_lambda：0.0
batch_size：1000
num_epochs：200
dev_sample_percentage：0.1
evaluate_every：1000
checkpoint_every：10000
num_checkpoints：500
试验结果：
1495329143文件
训练集的accuracy很高，将近于1
测试集由于设计的失败导致结果没有正确的显示出来
=================================================================